# 面部关键点检测

'''
我们已经学习了如何解决二分类(猫狗分类)和多分类( fashionMNIST )问题。
本节中，我们将学习如何解决回归问题，研究多个自变量对多个因变量的影响。
假如我们需要预测面部图像上的关键点，例如眼睛、鼻子和下巴的位置，就需要采用新的策略构建模型来检测面部关键点。
在本文中，我们将基于预训练 VGG16 架构提取图像特征，然后微调模型检测图像中人物面部关键点。
'''

# 1.关键点检测模型分析

# 1.1 关键点检测模型分析
'''
面部关键点检测( Facial Landmark Detection )旨在自动识别并捕捉面部照片或视频中的关键点位置，例如眼睛、鼻子、嘴巴、眉毛等。
通常使用深度学习算法通过对丰富的面部数据进行训练，自动提取面部特征，识别面部关键点位置，并将其标记在面部图片或视频的相应位置上。
面部关键点检测可以使计算机更好地理解和学习面部图像和视频中的信息，提取面部特征，为人脸识别、表情识别和面部特征分析等应用提供基础数据。

面部关键点表示包含人脸的图像上的各个关键点的标记。
要检测面部关键点，我们首先要解决以下问题：
    (1)图像具有不同的尺寸:
        调整图像尺寸以使它们具有标准图像尺寸。
    (2)面部关键点类似于散点图上的点，但其基于某种模式散布:
        将图像尺寸调整为 224 x 224 x 3, 像素介于 0 和 224 之间。
    (3)根据图像尺寸对因变量(面部关键点的位置)进行归一化:
        考虑它们相对于图像尺寸的位置，则关键点值介于 0 和 1 之间。
        由于因变量值始终介于 0 和 1 之间，因此可以在最后使用 sigmoid 函数来得到介于 0 和 1 之间的值。
    (4)定义用于加载数据集的数据管道：
        定义准备数据集的类，对输入图像进行预处理以执行迁移学习，并获取关键点相对于处理后的图像的相对位置。
    (5)定义模型、损失函数和优化器:
        使用平均绝对误差作为损失函数，因为输出是介于 0 到 1 之间的连续值。
'''

# 1.2 数据集分析
'''
对于面部关键点检测任务，我们所使用的数据集可以从 Github 中下载，数据集中标注了中图片的人物面部的关键点。
(下载地址: https://github.com/udacity/P1_Facial_Keypoints)
在此任务中，输入数据是需要在其上检测关键点的图像，输出数据是图像中人物面部关键点的 x 和 y 坐标。
在构建模型前，首先将数据集下载至本地，查看数据集中标记的面部关键点信息，文件路径为：
P1_Facial_Keypoints/data/training_frameS_KEYPOINTS.csv

检查此数据集中的面部关键点信息，可以看到，文件中共有 137 列，
其中第 1 列是图像的名称，
其余 136 列代表相应图像中 68 个面部关键点的 x 和 y 坐标值，
偶数列表示面部 68 个关键点中每个关键点对应的 x 轴坐标，
奇数列(第 1 列除外)表示面部 68 个关键点中每个关键点对应的 y 轴坐标。
'''

# 2.面部关键点检测

# 3. 2D和3D面部关键点检测